{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opencv haar을 이용해 crop 하기\n",
    "- 얼굴이 검출되면 눈이 있는지 확인하고 crop\n",
    "- 얼굴이 여러 개 검출되면 눈이 있는지 확인하고 가장 가능성 있는 부분 crop\n",
    "- 눈의 개수가 2개가 아니면 잘못 찾았다고 판단하고 정해진 부분 crop\n",
    "- 얼굴이 검출되지 않으면 정해진 부분 crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 크기 고정 240 x 350\n",
    "- 스케일 고려 x\n",
    "- 원본: 384 x 512 / crop: 240 x 350\n",
    "- 가끔 이상한 것들이 있지만 최대한 잘되는걸로!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### face, eye haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eye_casecade = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기타 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러개의 얼굴 중 중심에 더 가까운 box 선택\n",
    "def dist(center, mid): # center: 사진 중심, mid: box 중심 (x, y) \n",
    "    dist = ((center[0] - mid[0])**2 + (center[1] - mid[1])**2) ** (1/2)\n",
    "    return dist\n",
    "\n",
    "# 하나의 얼굴이 너무 벗어나지 않았는지 확인\n",
    "def face(center, xywh): # center: 사진 중심\n",
    "    if center[0] < xywh[0] or center[1] < xywh[1]:\n",
    "        return False\n",
    "    if center[0] > xywh[0]+xywh[2] or center[1] > xywh[1]+xywh[3]:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './train/train/images/'\n",
    "crop_path = './train/train/crop_images2/'\n",
    "person = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [05:12,  8.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for j, p in tqdm(enumerate(person)): # 사람\n",
    "    # print(p)\n",
    "    # 사진 종류 .jpg / .jpeg\n",
    "    images = glob.glob(os.path.join(path, p, '*.jpg'))\n",
    "    images += glob.glob(os.path.join(path, p, '*.jpeg'))\n",
    "    images += glob.glob(os.path.join(path, p, '*.png'))\n",
    "\n",
    "    for i, image in enumerate(images): # 이미지\n",
    "        img = cv2.imread(image)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.01,\n",
    "                minNeighbors=5,\n",
    "                minSize=(130, 130)\n",
    "        )\n",
    "\n",
    "        if len(faces) == 0: # 얼굴 X -> 정해진 사이즈 crop\n",
    "            cropped = img[80:80+350, 60:60+240]\n",
    "            \n",
    "        elif len(faces) == 1: # 얼굴 하나 검출\n",
    "            x, y, w, h = faces[0]\n",
    "            if face((180, 255), (x, y, w, h)): # 범위 안에 있다면 crop\n",
    "                mid_x, mid_y = max(120, x+w//2), max(175, y+h//2)\n",
    "                cropped = img[mid_y-175:mid_y+175, mid_x-120:mid_x+120]\n",
    "            else: # 범위 안에 없다면\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                roi_color = img[y:y+h, x:x+w]\n",
    "                eyes = eye_casecade.detectMultiScale(roi_gray, minSize=(35, 35))\n",
    "                if len(eyes) >= 2: # 그렇지만 눈 2개가 검출되면\n",
    "                    mid_x, mid_y = max(120, x+w//2), max(175, y+h//2)\n",
    "                    cropped = img[mid_y-175:mid_y+175, mid_x-120:mid_x+120]\n",
    "                else: # 아니면 -> 정해진 사이즈 crop\n",
    "                    cropped = img[80:80+350, 60:60+240]\n",
    "                    \n",
    "        else: # 얼굴 여러 개 검출\n",
    "            n_eyes = 0\n",
    "            center_dist = 500 # center에 가까운 얼굴 뽑기\n",
    "            max_eyes_xywh = (0, 0, 0, 0)\n",
    "            for (x, y, w, h) in faces:\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                roi_color = img[y:y+h, x:x+w]\n",
    "                eyes = eye_casecade.detectMultiScale(roi_gray, minSize=(35, 35))\n",
    "                c_dist = dist((180, 255), (x, y))\n",
    "                if len(eyes) >= n_eyes and center_dist > c_dist: # 눈의 개수가 더 많으면서, 더 center에 가까운\n",
    "                    n_eyes = len(eyes)\n",
    "                    max_eyes_xywh = (x, y, w, h)\n",
    "                    center_dist = c_dist\n",
    "            if n_eyes < 2: # 눈이 2개 미만이면 -> 정해진 사이즈 crop\n",
    "                cropped = img[80:80+350, 60:60+240]\n",
    "            else: # 아니면 가장 유력한 box\n",
    "                x, y, w, h = max_eyes_xywh\n",
    "                mid_x, mid_y = max(120, x+w//2), max(175, y+h//2)\n",
    "                cropped = img[mid_y-175:mid_y+175, mid_x-120:mid_x+120]\n",
    "        \n",
    "        # cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        make_path = crop_path + p \n",
    "        if not os.path.isdir(make_path): \n",
    "            os.mkdir(make_path)\n",
    "        save_path = os.path.join(make_path, image.split('\\\\')[-1])\n",
    "        cv2.imwrite(save_path, cropped)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사람 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './train/train/images/'\n",
    "crop_path = './train/train/crop_images2/'\n",
    "person = os.listdir(path)\n",
    "crop_person = os.listdir(crop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crop_person)  # 2627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006056_female_Asian_19 006075_male_Asian_18\n"
     ]
    }
   ],
   "source": [
    "for i, j  in zip(person, crop_person):\n",
    "    if i!=j:\n",
    "        print(i,j)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사진 다 7개인지 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [00:00, 3534.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for j, p in tqdm(enumerate(crop_person)): # 사람\n",
    "    # print(p)\n",
    "    # 사진 종류 .jpg / .jpeg\n",
    "    images = glob.glob(os.path.join(path, p, '*.jpg'))\n",
    "    images += glob.glob(os.path.join(path, p, '*.jpeg'))\n",
    "    images += glob.glob(os.path.join(path, p, '*.png'))\n",
    "    if len(images)!=7:\n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './train/eval/images/'\n",
    "crop_path = './train/eval/crop_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12600it [28:29,  7.37it/s]\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob(os.path.join(path, '*.jpg'))\n",
    "images += glob.glob(os.path.join(path, '*.jpeg'))\n",
    "# images += glob.glob(os.path.join(path, p, '*.png'))\n",
    "\n",
    "for i, image in tqdm(enumerate(images)): # 이미지\n",
    "    img = cv2.imread(image)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.01,\n",
    "            minNeighbors=5,\n",
    "            minSize=(130, 130)\n",
    "    )\n",
    "\n",
    "    if len(faces) == 0: # 얼굴 X -> 정해진 사이즈 crop\n",
    "        cropped = img[80:80+350, 60:60+240]\n",
    "\n",
    "    elif len(faces) == 1: # 얼굴 하나 검출\n",
    "        x, y, w, h = faces[0]\n",
    "        if face((180, 255), (x, y, w, h)): # 범위 안에 있다면 crop\n",
    "            mid_x, mid_y = max(120, x+w//2), max(175, y+h//2)\n",
    "            cropped = img[mid_y-175:mid_y+175, mid_x-120:mid_x+120]\n",
    "        else: # 범위 안에 없다면\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            eyes = eye_casecade.detectMultiScale(roi_gray, minSize=(35, 35))\n",
    "            if len(eyes) >= 2: # 그렇지만 눈 2개가 검출되면\n",
    "                mid_x, mid_y = max(120, x+w//2), max(175, y+h//2)\n",
    "                cropped = img[mid_y-175:mid_y+175, mid_x-120:mid_x+120]\n",
    "            else: # 아니면 -> 정해진 사이즈 crop\n",
    "                cropped = img[80:80+350, 60:60+240]\n",
    "\n",
    "    else: # 얼굴 여러 개 검출\n",
    "        n_eyes = 0\n",
    "        center_dist = 500 # center에 가까운 얼굴 뽑기\n",
    "        max_eyes_xywh = (0, 0, 0, 0)\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            eyes = eye_casecade.detectMultiScale(roi_gray, minSize=(35, 35))\n",
    "            c_dist = dist((180, 255), (x, y))\n",
    "            if len(eyes) >= n_eyes and center_dist > c_dist: # 눈의 개수가 더 많으면서, 더 center에 가까운\n",
    "                n_eyes = len(eyes)\n",
    "                max_eyes_xywh = (x, y, w, h)\n",
    "                center_dist = c_dist\n",
    "        if n_eyes < 2: # 눈이 2개 미만이면 -> 정해진 사이즈 crop\n",
    "            cropped = img[80:80+350, 60:60+240]\n",
    "        else: # 아니면 가장 유력한 box\n",
    "            x, y, w, h = max_eyes_xywh\n",
    "            mid_x, mid_y = max(120, x+w//2), max(175, y+h//2)\n",
    "            cropped = img[mid_y-175:mid_y+175, mid_x-120:mid_x+120]\n",
    "\n",
    "    # cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    save_path = os.path.join(crop_path, image.split('\\\\')[-1])\n",
    "    cv2.imwrite(save_path, cropped)\n",
    "    \n",
    "    time.sleep(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
